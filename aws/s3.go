package aws

import (
	"errors"
	"fmt"
	"hash/crc32"
	"strings"
	"time"

	"github.com/aws/aws-sdk-go/aws/awserr"
	"github.com/aws/aws-sdk-go/service/s3"
	"github.com/aws/aws-sdk-go/service/s3/s3iface"
	"github.com/aws/aws-sdk-go/service/s3/s3manager"
)

const bucketNameMaxLen = 63

type S3Settings struct {
	BucketName string
	Prefix     string
	KMSKeyID   string

	ThresholdSize int
}

func (cfg *S3Settings) Merge(otherCfg S3Settings) {
	if cfg.BucketName == "" {
		cfg.BucketName = otherCfg.BucketName
	}

	if cfg.Prefix == "" {
		cfg.Prefix = otherCfg.Prefix
	}

	if cfg.KMSKeyID == "" {
		cfg.KMSKeyID = otherCfg.KMSKeyID
	}

	if cfg.ThresholdSize == 0 {
		cfg.ThresholdSize = otherCfg.ThresholdSize
	}
}

func NewS3Uploader(mgr S3UploadManager, s3api s3iface.S3API, cfg S3Settings) *S3Uploader {
	return &S3Uploader{cfg: cfg, s3: s3api, mgr: mgr}
}

type S3Uploader struct {
	cfg S3Settings
	mgr S3UploadManager
	s3  s3iface.S3API

	autoGeneratedBucket string
}

func (s *S3Uploader) Upload(body string) (string, error) {
	maxSize := 51200

	if s.cfg.ThresholdSize != 0 {
		maxSize = s.cfg.ThresholdSize
	}

	if len(body) < maxSize {
		return "", nil // no need to do upload, the size is not over threshold
	}

	bucketName := s.cfg.BucketName

	if bucketName == "" {
		bucketName = fmt.Sprintf("stack-assembly-tmp-%d-%x", time.Now().UnixNano(), crc32.ChecksumIEEE([]byte(body)))
		if len(bucketName) > bucketNameMaxLen {
			bucketName = bucketName[:bucketNameMaxLen]
		}

		s.autoGeneratedBucket = bucketName
	}

	_, err := s.s3.CreateBucket(&s3.CreateBucketInput{
		Bucket: nilString(bucketName),
	})

	var aerr awserr.Error
	if err != nil && !(errors.As(err, &aerr) && aerr.Code() == s3.ErrCodeBucketAlreadyOwnedByYou) {
		return "", &BucketError{Op: "create s3 bucket", Bucket: bucketName, Err: err}
	}

	err = s.s3.WaitUntilBucketExists(&s3.HeadBucketInput{Bucket: nilString(bucketName)})
	if err != nil {
		return "", &BucketError{Op: "create s3 bucket", Bucket: bucketName, Err: err}
	}

	prefix := s.cfg.Prefix
	if prefix == "" {
		prefix = "stack-assembly"
	}

	r, err := s.mgr.Upload(&s3manager.UploadInput{
		Bucket:      nilString(bucketName),
		Key:         nilString(prefix),
		SSEKMSKeyId: nilString(s.cfg.KMSKeyID),
		Body:        strings.NewReader(body),
	})
	if err != nil {
		return "", &BucketError{Op: "upload template to s3", Bucket: bucketName, Err: err}
	}

	return r.Location, nil
}

func (s S3Uploader) Cleanup() error {
	if s.autoGeneratedBucket == "" {
		return nil
	}

	// we don't care about paging as there is only one object in
	// autogenerated bucket

	objects, err := s.s3.ListObjects(&s3.ListObjectsInput{Bucket: &s.autoGeneratedBucket})
	if err != nil {
		return &BucketError{Op: "remove tmp s3 bucket", Bucket: s.autoGeneratedBucket, Err: err}
	}

	ids := make([]*s3.ObjectIdentifier, 0, len(objects.Contents))
	for _, obj := range objects.Contents {
		ids = append(ids, &s3.ObjectIdentifier{Key: obj.Key})
	}

	_, err = s.s3.DeleteObjects(&s3.DeleteObjectsInput{
		Bucket: &s.autoGeneratedBucket,
		Delete: &s3.Delete{Objects: ids},
	})
	if err != nil {
		return &BucketError{Op: "remove tmp s3 bucket", Bucket: s.autoGeneratedBucket, Err: err}
	}

	_, err = s.s3.DeleteBucket(&s3.DeleteBucketInput{Bucket: &s.autoGeneratedBucket})
	if err != nil {
		return &BucketError{Op: "remove tmp s3 bucket", Bucket: s.autoGeneratedBucket, Err: err}
	}

	return nil
}

type S3UploadManager interface {
	Upload(*s3manager.UploadInput, ...func(*s3manager.Uploader)) (*s3manager.UploadOutput, error)
}

type BucketError struct {
	Op     string
	Bucket string
	Err    error
}

func (e *BucketError) Unwrap() error { return e.Err }
func (e *BucketError) Error() string {
	return fmt.Sprintf("operation '%s' failed for bucket %s: %s", e.Op, e.Bucket, e.Err)
}
